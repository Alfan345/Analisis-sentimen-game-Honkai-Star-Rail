{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install dan Import Library"
      ],
      "metadata": {
        "id": "0imD7EIJHRQd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzxYlsQyL-Vt",
        "outputId": "529adacd-175c-470a-8591-2db317ca16c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-play-scraper\n",
            "  Downloading google_play_scraper-1.2.7-py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_play_scraper-1.2.7-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: google-play-scraper\n",
            "Successfully installed google-play-scraper-1.2.7\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Collecting Sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl.metadata (909 bytes)\n",
            "Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Sastrawi\n",
            "Successfully installed Sastrawi-1.0.1\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.11/dist-packages (1.9.4)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from wordcloud) (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from wordcloud) (11.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from wordcloud) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.17.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.11/dist-packages (from seaborn) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install google-play-scraper\n",
        "!pip install nltk\n",
        "!pip install Sastrawi\n",
        "!pip install wordcloud\n",
        "!pip install seaborn\n",
        "!pip install tensorflow\n",
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rd1xCp2RMC4f",
        "outputId": "46f6341c-deba-4948-b002-50298a6b35fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# Text processing\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "\n",
        "# Machine learning\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Deep learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, SpatialDropout1D, GRU, GlobalMaxPooling1D, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mengambil data ulasan"
      ],
      "metadata": {
        "id": "oHCU7tgdHa5p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yn87GY2BMFOo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "d0a99083-29b4-4057-a7c8-976cd8b7f86c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               reviewId         userName  \\\n",
              "0  32063696-a983-49ac-8378-8b99cda18013  Pengguna Google   \n",
              "1  21eaa8ba-36ef-4441-97ea-112607515be0  Pengguna Google   \n",
              "2  46fa15e9-6c03-4048-add2-8f47fe55caf7  Pengguna Google   \n",
              "3  ebaa30c5-ddc7-448b-b4e3-34dacecaf748  Pengguna Google   \n",
              "4  11e55296-1306-4ca8-b365-c58b6ddc5f73  Pengguna Google   \n",
              "\n",
              "                                           userImage  \\\n",
              "0  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
              "1  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
              "2  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
              "3  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
              "4  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
              "\n",
              "                                             content  score  thumbsUpCount  \\\n",
              "0  cut scene, character, bangunan, grafik,alur ce...      5            178   \n",
              "1  Penulisan ceritanya cukup bagus bisa ditingkat...      5              3   \n",
              "2  Banyak kemunduran dalam perkembangan game ini,...      1             26   \n",
              "3  Visual oke, gameplay mudah dipahami, story lum...      4              7   \n",
              "4  saya sangat suka dengan game ini , semenjak up...      5             28   \n",
              "\n",
              "  reviewCreatedVersion                  at replyContent repliedAt appVersion  \n",
              "0                3.2.0 2025-04-09 11:21:03         None       NaT      3.2.0  \n",
              "1                3.2.0 2025-04-16 11:56:51         None       NaT      3.2.0  \n",
              "2                3.2.0 2025-04-15 06:23:45         None       NaT      3.2.0  \n",
              "3                3.2.0 2025-04-09 03:20:15         None       NaT      3.2.0  \n",
              "4                3.2.0 2025-04-12 13:57:43         None       NaT      3.2.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f9443a8-1a81-4900-8a74-7c7c8c0c8da6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewId</th>\n",
              "      <th>userName</th>\n",
              "      <th>userImage</th>\n",
              "      <th>content</th>\n",
              "      <th>score</th>\n",
              "      <th>thumbsUpCount</th>\n",
              "      <th>reviewCreatedVersion</th>\n",
              "      <th>at</th>\n",
              "      <th>replyContent</th>\n",
              "      <th>repliedAt</th>\n",
              "      <th>appVersion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>32063696-a983-49ac-8378-8b99cda18013</td>\n",
              "      <td>Pengguna Google</td>\n",
              "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
              "      <td>cut scene, character, bangunan, grafik,alur ce...</td>\n",
              "      <td>5</td>\n",
              "      <td>178</td>\n",
              "      <td>3.2.0</td>\n",
              "      <td>2025-04-09 11:21:03</td>\n",
              "      <td>None</td>\n",
              "      <td>NaT</td>\n",
              "      <td>3.2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21eaa8ba-36ef-4441-97ea-112607515be0</td>\n",
              "      <td>Pengguna Google</td>\n",
              "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
              "      <td>Penulisan ceritanya cukup bagus bisa ditingkat...</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3.2.0</td>\n",
              "      <td>2025-04-16 11:56:51</td>\n",
              "      <td>None</td>\n",
              "      <td>NaT</td>\n",
              "      <td>3.2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>46fa15e9-6c03-4048-add2-8f47fe55caf7</td>\n",
              "      <td>Pengguna Google</td>\n",
              "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
              "      <td>Banyak kemunduran dalam perkembangan game ini,...</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>3.2.0</td>\n",
              "      <td>2025-04-15 06:23:45</td>\n",
              "      <td>None</td>\n",
              "      <td>NaT</td>\n",
              "      <td>3.2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ebaa30c5-ddc7-448b-b4e3-34dacecaf748</td>\n",
              "      <td>Pengguna Google</td>\n",
              "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
              "      <td>Visual oke, gameplay mudah dipahami, story lum...</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>3.2.0</td>\n",
              "      <td>2025-04-09 03:20:15</td>\n",
              "      <td>None</td>\n",
              "      <td>NaT</td>\n",
              "      <td>3.2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11e55296-1306-4ca8-b365-c58b6ddc5f73</td>\n",
              "      <td>Pengguna Google</td>\n",
              "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
              "      <td>saya sangat suka dengan game ini , semenjak up...</td>\n",
              "      <td>5</td>\n",
              "      <td>28</td>\n",
              "      <td>3.2.0</td>\n",
              "      <td>2025-04-12 13:57:43</td>\n",
              "      <td>None</td>\n",
              "      <td>NaT</td>\n",
              "      <td>3.2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f9443a8-1a81-4900-8a74-7c7c8c0c8da6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9f9443a8-1a81-4900-8a74-7c7c8c0c8da6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9f9443a8-1a81-4900-8a74-7c7c8c0c8da6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ebc4f99f-ce92-4f94-b033-66ea8e516f28\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ebc4f99f-ce92-4f94-b033-66ea8e516f28')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ebc4f99f-ce92-4f94-b033-66ea8e516f28 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_review",
              "summary": "{\n  \"name\": \"df_review\",\n  \"rows\": 5000,\n  \"fields\": [\n    {\n      \"column\": \"reviewId\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5000,\n        \"samples\": [\n          \"a3bd74da-075e-4f98-8d0a-d0d9226a6e86\",\n          \"9d0153a8-149a-4e65-8e66-da1b454eb4b9\",\n          \"2dafb2ea-bfe9-4d11-a864-9f1e46f8b250\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"userName\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 501,\n        \"samples\": [\n          \"Yunoo\",\n          \"Nama tak berarti\",\n          \"G Dylan Farrel D\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"userImage\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 501,\n        \"samples\": [\n          \"https://play-lh.googleusercontent.com/a-/ALV-UjXAScCyxDjhIfvxpofhBZVN5kIgZDCvBFaJ55-blkeethXy2fLU\",\n          \"https://play-lh.googleusercontent.com/a-/ALV-UjVHM7NSXlno9OB4bRtDFJETQ-zw6fgSRRgrfcsysOV80KlIF2Cg\",\n          \"https://play-lh.googleusercontent.com/a-/ALV-UjXZiAhxBPPFJ8QCpQTtnhSLoAycZZ3pjiqMP02CLVSe5EOa8H8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4990,\n        \"samples\": [\n          \"Game yang seru dan cukup menantang, namun bisa bermain dengan santai, alur cerita yang menarik dan seru membuat game menjadi unik.\",\n          \"Game tidak ramah HP kentang, main full party nihility berasa hp juga kena DoT juga, dikit dikit ngelag akibat efek DoT, pas kafka ulti bilang BOOM, HP ku langsung kerestart sendiri, :( plis mang hoyo efek DoT di peramah sedikit\",\n          \"Sejak update 1.1, jadi force close mulu masih banyak bugnya di android tolong segera diperbaiki saya jadi tidak bisa mainkan gamenya.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          3,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thumbsUpCount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 78,\n        \"min\": 0,\n        \"max\": 3897,\n        \"num_unique_values\": 161,\n        \"samples\": [\n          277,\n          342,\n          386\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reviewCreatedVersion\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"3.2.0\",\n          \"3.1.0\",\n          \"2.0.0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"at\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2023-04-23 04:31:48\",\n        \"max\": \"2025-04-16 16:06:46\",\n        \"num_unique_values\": 4997,\n        \"samples\": [\n          \"2025-04-06 15:08:39\",\n          \"2025-04-06 23:51:41\",\n          \"2023-10-07 07:52:31\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"replyContent\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"Mohon maaf sebesar-besarnya atas terganggunya pengalaman bermain Trailblazer. Silakan hubungi Layanan Customer Support kami melalui email untuk mendapatkan bantuan tentang masalah ini.\",\n          \"Terima kasih atas dukungan Trailblazer untuk Honkai: Star Rail. Kami sangat menghargai setiap masukan yang berharga dari kalian. Jika Trailblazer memiliki saran atau masukan lain yang ingin anda sampaikan, jangan ragu untuk menghubungi kami melalui feedback in-game atau email.\",\n          \"Kami mohon maaf atas ketidaknyamanan yang Anda alami, Trailblazer.\\n\\nKalau Anda memiliki masukan atau saran, silakan hubungi kami melalui email atau feedback in-game.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"repliedAt\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2024-03-19 06:19:46\",\n        \"max\": \"2025-03-20 10:40:22\",\n        \"num_unique_values\": 236,\n        \"samples\": [\n          \"2025-01-10 07:24:57\",\n          \"2025-03-06 09:20:01\",\n          \"2024-03-19 08:07:41\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"appVersion\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"3.2.0\",\n          \"3.1.0\",\n          \"2.0.0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from google_play_scraper import Sort, reviews\n",
        "\n",
        "# Scrape reviews\n",
        "scrapreview, continuation_token = reviews(\n",
        "    'com.HoYoverse.hkrpgoversea',\n",
        "    lang='id',\n",
        "    country='id',\n",
        "    sort=Sort.MOST_RELEVANT,\n",
        "    count=5000,  # Increased sample size\n",
        "    filter_score_with=None\n",
        ")\n",
        "\n",
        "# Load data dari hasil scraping yang sudah disimpan\n",
        "df_review = pd.read_csv('https://raw.githubusercontent.com/Alfan345/Analisis-sentimen-game-Honkai-Star-Rail/refs/heads/main/ulasan_aplikasi.csv')  # pastikan file ini tersedia\n",
        "df_review = pd.DataFrame(scrapreview)\n",
        "df_review.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-processing data"
      ],
      "metadata": {
        "id": "x81B3-JDHn4n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R50Fp9QvMHLX",
        "outputId": "202ab01a-086e-4b0f-a448-f12a67a52d52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "<ipython-input-4-f183d2b4be95>:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  my_df['Label'] = my_df['score'].apply(label_score)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "Positif    3189\n",
            "Negatif    1392\n",
            "Netral      419\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import string, requests, json\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "\n",
        "# Labeling based on score\n",
        "def label_score(score):\n",
        "    if score < 3:\n",
        "        return 'Negatif'\n",
        "    elif score == 3:\n",
        "        return 'Netral'\n",
        "    elif score >= 4:\n",
        "        return 'Positif'\n",
        "\n",
        "my_df = df_review[['userName', 'score', 'at', 'content']]\n",
        "my_df['Label'] = my_df['score'].apply(label_score)\n",
        "\n",
        "# Check class distribution\n",
        "print(my_df['Label'].value_counts())\n",
        "\n",
        "# Balance the dataset\n",
        "from sklearn.utils import resample\n",
        "df_neg = my_df[my_df['Label'] == 'Negatif']\n",
        "df_net = my_df[my_df['Label'] == 'Netral']\n",
        "df_pos = my_df[my_df['Label'] == 'Positif']\n",
        "\n",
        "# Upsample minority classes\n",
        "df_neg_upsampled = resample(df_neg, replace=True, n_samples=len(df_pos), random_state=42)\n",
        "df_net_upsampled = resample(df_net, replace=True, n_samples=len(df_pos), random_state=42)\n",
        "\n",
        "# Combine majority class with upsampled minority classes\n",
        "my_df = pd.concat([df_pos, df_neg_upsampled, df_net_upsampled])\n",
        "\n",
        "# Ambil slangword\n",
        "get_slangs = requests.get('https://raw.githubusercontent.com/louisowen6/NLP_bahasa_resources/refs/heads/master/combined_slang_words.txt')\n",
        "slangwords = json.loads(get_slangs.text) if get_slangs.status_code == 200 else {}\n",
        "\n",
        "def cleaningText(text):\n",
        "    text = re.sub(r'@[A-Za-z0-9]+', '', text)\n",
        "    text = re.sub(r'#[A-Za-z0-9]+', '', text)\n",
        "    text = re.sub(r'RT[\\s]', '', text)\n",
        "    text = re.sub(r\"http\\S+\", '', text)\n",
        "    text = re.sub(r'[0-9]+', '', text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = text.replace('\\n', ' ')\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    return text.strip()\n",
        "\n",
        "def casefoldingText(text):\n",
        "    return text.lower()\n",
        "\n",
        "def tokenizingText(text):\n",
        "    # Daripada word_tokenize (yang butuh punkt), gunakan split\n",
        "    return text.split()\n",
        "\n",
        "\n",
        "def lemmatingText(text):\n",
        "    wnl = WordNetLemmatizer()\n",
        "    return ' '.join([wnl.lemmatize(word, pos='v') for word in text])\n",
        "\n",
        "def fix_slangwords(text):\n",
        "    return ' '.join([slangwords.get(word, word) for word in text.split()])\n",
        "\n",
        "def filteringText(words):\n",
        "    factory = StopWordRemoverFactory()\n",
        "    stopwords = set(factory.get_stop_words())\n",
        "    return [word for word in words if word not in stopwords]\n",
        "\n",
        "def toSentence(word_list):\n",
        "    return ' '.join(word_list)\n",
        "\n",
        "my_df['processed'] = my_df['content'].astype(str).apply(cleaningText)\n",
        "my_df['processed'] = my_df['processed'].apply(casefoldingText)\n",
        "my_df['processed'] = my_df['processed'].apply(fix_slangwords)\n",
        "my_df['processed'] = my_df['processed'].apply(tokenizingText)    # ← pakai split sekarang\n",
        "my_df['processed'] = my_df['processed'].apply(filteringText)\n",
        "my_df['processed'] = my_df['processed'].apply(lemmatingText)\n",
        "\n",
        "# Terakhir, stemming\n",
        "stemmer_factory = StemmerFactory()\n",
        "stemmer = stemmer_factory.create_stemmer()\n",
        "my_df['content_stemmed'] = my_df['processed'].apply(lambda x: stemmer.stem(x))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "set_seed(42)"
      ],
      "metadata": {
        "id": "gRoEcOZS0-Re"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "tXQdR8j7MJbY"
      },
      "outputs": [],
      "source": [
        "# Split data\n",
        "X = my_df['content_stemmed']\n",
        "y = my_df['Label']\n",
        "\n",
        "# Encode labels\n",
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(y)\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pelatihan Model"
      ],
      "metadata": {
        "id": "OI_QAhJ5Hxk7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wfI5aUcMNFV",
        "outputId": "578bd379-6902-4072-ec73-a60d3fefa5fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Classifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Negatif       0.86      0.94      0.90       638\n",
            "      Netral       0.94      0.99      0.97       638\n",
            "     Positif       0.94      0.81      0.87       638\n",
            "\n",
            "    accuracy                           0.91      1914\n",
            "   macro avg       0.91      0.91      0.91      1914\n",
            "weighted avg       0.91      0.91      0.91      1914\n",
            "\n",
            "Accuracy: 0.9107\n"
          ]
        }
      ],
      "source": [
        "# Create a pipeline with TF-IDF and classifier\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(\n",
        "        max_features=10000,\n",
        "        ngram_range=(1, 2),  # Use unigrams and bigrams\n",
        "        min_df=5,\n",
        "        max_df=0.7\n",
        "    )),\n",
        "    ('clf', GradientBoostingClassifier(\n",
        "        n_estimators=200,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=5,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train the model\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = pipeline.predict(X_test)\n",
        "print(\"Gradient Boosting Classifier:\")\n",
        "print(classification_report(y_test, y_pred, target_names=encoder.classes_))\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "# Tokenizer dan padding ulang\n",
        "tokenizer = Tokenizer(num_words=20000, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "max_len = 200\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post', truncating='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post', truncating='post')\n",
        "\n",
        "\n",
        "# Model GRU\n",
        "model_gru = Sequential([\n",
        "    Embedding(input_dim=20000, output_dim=128),\n",
        "    SpatialDropout1D(0.3),\n",
        "    Bidirectional(GRU(128, return_sequences=True, dropout=0.3, recurrent_dropout=0.3)),\n",
        "    GlobalMaxPooling1D(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model_gru.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'best_gru_model.h5', monitor='val_accuracy',\n",
        "    save_best_only=True, mode='max', verbose=1\n",
        ")\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_accuracy', patience=5,\n",
        "    mode='max', restore_best_weights=True\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_accuracy', factor=0.5,\n",
        "    patience=2, min_lr=1e-5, verbose=1, mode='max'\n",
        ")\n",
        "\n",
        "history = model_gru.fit(\n",
        "    X_train_pad, y_train,\n",
        "    validation_split=0.1,\n",
        "    epochs=20,\n",
        "    batch_size=128,\n",
        "    callbacks=[early_stopping, reduce_lr, checkpoint],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluasi\n",
        "model_gru.load_weights('best_gru_model.h5')\n",
        "\n",
        "y_pred = model_gru.predict(X_test_pad)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "print(\"\\n📊 GRU Model Evaluation:\")\n",
        "print(classification_report(y_test, y_pred, target_names=encoder.classes_))\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nzm3Orpa2MSw",
        "outputId": "97e302a5-27bc-4cff-b4f0-f98e344b7376"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.3498 - loss: 1.0970\n",
            "Epoch 1: val_accuracy improved from -inf to 0.47911, saving model to best_gru_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 3s/step - accuracy: 0.3501 - loss: 1.0970 - val_accuracy: 0.4791 - val_loss: 1.0858 - learning_rate: 3.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.4353 - loss: 1.0817\n",
            "Epoch 2: val_accuracy improved from 0.47911 to 0.58486, saving model to best_gru_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 3s/step - accuracy: 0.4357 - loss: 1.0815 - val_accuracy: 0.5849 - val_loss: 1.0302 - learning_rate: 3.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5613 - loss: 0.9841\n",
            "Epoch 3: val_accuracy improved from 0.58486 to 0.62794, saving model to best_gru_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 3s/step - accuracy: 0.5619 - loss: 0.9831 - val_accuracy: 0.6279 - val_loss: 0.8094 - learning_rate: 3.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.6649 - loss: 0.7668\n",
            "Epoch 4: val_accuracy improved from 0.62794 to 0.76893, saving model to best_gru_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 3s/step - accuracy: 0.6656 - loss: 0.7660 - val_accuracy: 0.7689 - val_loss: 0.6306 - learning_rate: 3.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7814 - loss: 0.5776\n",
            "Epoch 5: val_accuracy improved from 0.76893 to 0.81462, saving model to best_gru_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 3s/step - accuracy: 0.7818 - loss: 0.5767 - val_accuracy: 0.8146 - val_loss: 0.4956 - learning_rate: 3.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8609 - loss: 0.4000\n",
            "Epoch 6: val_accuracy improved from 0.81462 to 0.86554, saving model to best_gru_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 3s/step - accuracy: 0.8611 - loss: 0.3994 - val_accuracy: 0.8655 - val_loss: 0.3962 - learning_rate: 3.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9096 - loss: 0.2968\n",
            "Epoch 7: val_accuracy improved from 0.86554 to 0.89295, saving model to best_gru_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 3s/step - accuracy: 0.9098 - loss: 0.2963 - val_accuracy: 0.8930 - val_loss: 0.3356 - learning_rate: 3.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9261 - loss: 0.2294\n",
            "Epoch 8: val_accuracy improved from 0.89295 to 0.89948, saving model to best_gru_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 3s/step - accuracy: 0.9263 - loss: 0.2290 - val_accuracy: 0.8995 - val_loss: 0.3216 - learning_rate: 3.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9479 - loss: 0.1683\n",
            "Epoch 9: val_accuracy improved from 0.89948 to 0.90339, saving model to best_gru_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3s/step - accuracy: 0.9479 - loss: 0.1682 - val_accuracy: 0.9034 - val_loss: 0.3192 - learning_rate: 3.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9508 - loss: 0.1623\n",
            "Epoch 10: val_accuracy did not improve from 0.90339\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 3s/step - accuracy: 0.9509 - loss: 0.1620 - val_accuracy: 0.9008 - val_loss: 0.3336 - learning_rate: 3.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9596 - loss: 0.1294\n",
            "Epoch 11: val_accuracy improved from 0.90339 to 0.91253, saving model to best_gru_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 3s/step - accuracy: 0.9597 - loss: 0.1292 - val_accuracy: 0.9125 - val_loss: 0.3024 - learning_rate: 3.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9643 - loss: 0.1127\n",
            "Epoch 12: val_accuracy did not improve from 0.91253\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 3s/step - accuracy: 0.9644 - loss: 0.1124 - val_accuracy: 0.9060 - val_loss: 0.3529 - learning_rate: 3.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9714 - loss: 0.0939\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.91253\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 3s/step - accuracy: 0.9715 - loss: 0.0938 - val_accuracy: 0.9047 - val_loss: 0.3442 - learning_rate: 3.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9779 - loss: 0.0757\n",
            "Epoch 14: val_accuracy did not improve from 0.91253\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 3s/step - accuracy: 0.9779 - loss: 0.0757 - val_accuracy: 0.9112 - val_loss: 0.3372 - learning_rate: 1.5000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9785 - loss: 0.0719\n",
            "Epoch 15: val_accuracy improved from 0.91253 to 0.91775, saving model to best_gru_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 3s/step - accuracy: 0.9785 - loss: 0.0718 - val_accuracy: 0.9178 - val_loss: 0.3306 - learning_rate: 1.5000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9795 - loss: 0.0702\n",
            "Epoch 16: val_accuracy did not improve from 0.91775\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 3s/step - accuracy: 0.9796 - loss: 0.0701 - val_accuracy: 0.9125 - val_loss: 0.3399 - learning_rate: 1.5000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9818 - loss: 0.0612\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.91775\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 3s/step - accuracy: 0.9818 - loss: 0.0612 - val_accuracy: 0.9151 - val_loss: 0.3373 - learning_rate: 1.5000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9826 - loss: 0.0609\n",
            "Epoch 18: val_accuracy did not improve from 0.91775\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 3s/step - accuracy: 0.9827 - loss: 0.0608 - val_accuracy: 0.9151 - val_loss: 0.3403 - learning_rate: 7.5000e-05\n",
            "Epoch 19/20\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9820 - loss: 0.0620\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 3.7500001781154424e-05.\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.91775\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 3s/step - accuracy: 0.9820 - loss: 0.0618 - val_accuracy: 0.9164 - val_loss: 0.3280 - learning_rate: 7.5000e-05\n",
            "Epoch 20/20\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9836 - loss: 0.0547\n",
            "Epoch 20: val_accuracy did not improve from 0.91775\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 3s/step - accuracy: 0.9836 - loss: 0.0546 - val_accuracy: 0.9151 - val_loss: 0.3329 - learning_rate: 3.7500e-05\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 142ms/step\n",
            "\n",
            "📊 GRU Model Evaluation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Negatif       0.90      0.92      0.91       638\n",
            "      Netral       0.92      0.99      0.96       638\n",
            "     Positif       0.94      0.85      0.89       638\n",
            "\n",
            "    accuracy                           0.92      1914\n",
            "   macro avg       0.92      0.92      0.92      1914\n",
            "weighted avg       0.92      0.92      0.92      1914\n",
            "\n",
            "Accuracy: 0.9216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "e7uH0yYpH12A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_for_inference(text):\n",
        "    text = cleaningText(text)\n",
        "    text = fix_slangwords(text)\n",
        "    tokens = filteringText(tokenizingText(text))\n",
        "    text = lemmatingText(toSentence(tokens))\n",
        "    text = stemmer.stem(text)\n",
        "    return text\n",
        "\n",
        "def predict_sentiment_gru(text):\n",
        "    cleaned = preprocess_for_inference(text)\n",
        "    seq = tokenizer.texts_to_sequences([cleaned])\n",
        "    pad = pad_sequences(seq, maxlen=max_len, padding='post', truncating='post')\n",
        "    pred_idx = np.argmax(model_gru.predict(pad), axis=1)[0]\n",
        "    return encoder.classes_[pred_idx]\n",
        "\n",
        "inference_samples = [\n",
        "    \"game ini bikin nagih banget, seru parah!\",\n",
        "    \"fitur-fiturnya terlalu ribet dan berat\",\n",
        "    \"grafik dan animasinya oke, tapi loading lama\",\n",
        "    \"biasa aja sih, gak spesial\",\n",
        "    \"sangat membantu untuk mengisi waktu luang\",\n",
        "    \"game nya jelek banget, uninstall langsung\",\n",
        "    \"Performanya belum di optimalisasikan disemua perangkat\"\n",
        "]\n",
        "\n",
        "print(\"\\n Inference dengan GRU Model:\")\n",
        "for i, sample in enumerate(inference_samples, 1):\n",
        "    pred = predict_sentiment_gru(sample)\n",
        "    print(f\"{i}. \\\"{sample}\\\" → Prediksi: {pred}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOgeDSgkE6gG",
        "outputId": "c789b09a-7ec1-4a74-e7b9-2f152dca6004"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Inference dengan GRU Model:\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step\n",
            "1. \"game ini bikin nagih banget, seru parah!\" → Prediksi: Positif\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step\n",
            "2. \"fitur-fiturnya terlalu ribet dan berat\" → Prediksi: Positif\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "3. \"grafik dan animasinya oke, tapi loading lama\" → Prediksi: Negatif\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step\n",
            "4. \"biasa aja sih, gak spesial\" → Prediksi: Positif\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step\n",
            "5. \"sangat membantu untuk mengisi waktu luang\" → Prediksi: Positif\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
            "6. \"game nya jelek banget, uninstall langsung\" → Prediksi: Negatif\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
            "7. \"Performanya belum di optimalisasikan disemua perangkat\" → Prediksi: Positif\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}